{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>백설공주는 왜 백설공주라는 이름을 가지게 되었나요?</td>\n",
       "      <td>백설공주는 피부가 눈처럼 하얗고 아름다워서백설공주라는 이름을 가지게 되었어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>백설공주를 죽이려고 했던 사람은 누구인가요?</td>\n",
       "      <td>백설공주의 새어머니인 왕비가 백설공주를 죽이려고 했어요. 왕비는 자신이 세상에서 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>백설공주는 어떤 음식을 먹고 쓰러졌나요?</td>\n",
       "      <td>백설공주는 빨간 독사과를 먹고 쓰러졌어요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       question  \\\n",
       "0  백설공주는 왜 백설공주라는 이름을 가지게 되었나요?   \n",
       "1      백설공주를 죽이려고 했던 사람은 누구인가요?   \n",
       "2        백설공주는 어떤 음식을 먹고 쓰러졌나요?   \n",
       "\n",
       "                                              answer  \n",
       "0        백설공주는 피부가 눈처럼 하얗고 아름다워서백설공주라는 이름을 가지게 되었어요.  \n",
       "1  백설공주의 새어머니인 왕비가 백설공주를 죽이려고 했어요. 왕비는 자신이 세상에서 가...  \n",
       "2                            백설공주는 빨간 독사과를 먹고 쓰러졌어요.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 질문, 답변 목록\n",
    "inputs = [\n",
    "    \"백설공주는 왜 백설공주라는 이름을 가지게 되었나요?\",\n",
    "    \"백설공주를 죽이려고 했던 사람은 누구인가요?\",\n",
    "    \"백설공주는 어떤 음식을 먹고 쓰러졌나요?\"\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    \"백설공주는 피부가 눈처럼 하얗고 아름다워서백설공주라는 이름을 가지게 되었어요.\",\n",
    "    \"백설공주의 새어머니인 왕비가 백설공주를 죽이려고 했어요. 왕비는 자신이 세상에서 가장 아름다운 사람이 되고싶어서 백설공주를 질투했기 때문이에요\",\n",
    "    \"백설공주는 빨간 독사과를 먹고 쓰러졌어요.\"\n",
    "]\n",
    "\n",
    "# 답변 쌍으로 만들기\n",
    "# zip() : 파이썬 내장함수 여러개의 반복가능한 객체들을 병렬적으로 묶어주는 역할\n",
    "qa_pairs = [{\"question\": q, \"answer\":a} for q, a in zip(inputs, outputs)]\n",
    "\n",
    "df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"RAG_EVALUATION_DATASET\"\n",
    "\n",
    "def create_dataset(client, datatset_name, description=None):\n",
    "\n",
    "    # 기존의 모든 데이터셋을 순회\n",
    "    for dataset in client.list_datasets():\n",
    "        # 동일한 이름의 데이터셋이 이미 존재하면 기존 데이터셋 반환\n",
    "        if dataset.name == dataset_name:\n",
    "            return dataset\n",
    "    \n",
    "    # 동일 이름의 데이터셋이 없으면 새로운 데이터셋 생성\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name, # 데이터셋 이름 설정\n",
    "        description=description    # 데이터셋 설명 설정\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "#데이터셋 생성\n",
    "dataset = create_dataset(client, dataset_name)\n",
    "\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in df[\"question\"].tolist()],\n",
    "    outputs=[{\"answer\": a} for a in df[\"answer\"].tolist()],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a teacher grading a quiz.\n",
      "You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\n",
      "\n",
      "Example Format:\n",
      "QUESTION: question here\n",
      "STUDENT ANSWER: student's answer here\n",
      "TRUE ANSWER: true answer here\n",
      "GRADE: CORRECT or INCORRECT here\n",
      "\n",
      "Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \n",
      "\n",
      "QUESTION: \u001b[33;1m\u001b[1;3m{query}\u001b[0m\n",
      "STUDENT ANSWER: \u001b[33;1m\u001b[1;3m{result}\u001b[0m\n",
      "TRUE ANSWER: \u001b[33;1m\u001b[1;3m{answer}\u001b[0m\n",
      "GRADE:\n",
      "View the evaluation results for experiment: 'RAG_EVALUATION-d642b324' at:\n",
      "https://smith.langchain.com/o/4f4b6069-9fa7-4219-889b-6de7c9b52ea4/datasets/d27aef40-c129-4c8c-85da-f16249bcb82f/compare?selectedSessions=4989d06d-7a59-4fba-8b5b-576e2b5f1247\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:05,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a teacher grading a quiz.\n",
      "You are given a question, the context the question is about, and the student's answer. You are asked to score the student's answer as either CORRECT or INCORRECT, based on the context.\n",
      "Write out in a step by step manner your reasoning to be sure that your conclusion is correct. Avoid simply stating the correct answer at the outset.\n",
      "\n",
      "Example Format:\n",
      "QUESTION: question here\n",
      "CONTEXT: context the question is about here\n",
      "STUDENT ANSWER: student's answer here\n",
      "EXPLANATION: step by step reasoning here\n",
      "GRADE: CORRECT or INCORRECT here\n",
      "\n",
      "Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \n",
      "\n",
      "QUESTION: \u001b[33;1m\u001b[1;3m{query}\u001b[0m\n",
      "CONTEXT: \u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "STUDENT ANSWER: \u001b[33;1m\u001b[1;3m{result}\u001b[0m\n",
      "EXPLANATION:\n",
      "View the evaluation results for experiment: 'RAG_EVALUATION-4b520cc8' at:\n",
      "https://smith.langchain.com/o/4f4b6069-9fa7-4219-889b-6de7c9b52ea4/datasets/d27aef40-c129-4c8c-85da-f16249bcb82f/compare?selectedSessions=981ac19a-9029-40b4-a754-892ebe650161\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Error running evaluator <DynamicRunEvaluator evaluate> on run 7c2532bc-a1ed-4f6d-b085-de4a41bd0d94: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9748, Requested 604. Please try again in 2.112s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9748, Requested 604. Please try again in 2.112s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "2it [00:09,  4.37s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run a53c7341-d9ba-4bc2-8c70-ceeefbc4aa35: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9837, Requested 604. Please try again in 2.646s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9837, Requested 604. Please try again in 2.646s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 0a32c0c9-8769-40d3-bb13-f6c4c8a6cbcf: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9917, Requested 652. Please try again in 3.414s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9917, Requested 652. Please try again in 3.414s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "4it [00:13,  2.68s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run bd101bad-f0a4-465c-bd1c-758d09e723ef: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9836, Requested 735. Please try again in 3.426s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9836, Requested 735. Please try again in 3.426s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "5it [00:13,  1.95s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 569af250-f1ea-4b5c-a46a-5b3e2066f3ad: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9807, Requested 770. Please try again in 3.462s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9807, Requested 770. Please try again in 3.462s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "6it [00:13,  1.41s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 5c568fc1-4fef-46e0-9c2e-2d99f37351d2: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9806, Requested 770. Please try again in 3.456s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9806, Requested 770. Please try again in 3.456s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "8it [00:16,  1.48s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run e0e85eab-3f4f-469d-9e6c-ab2097420d7f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9841, Requested 735. Please try again in 3.456s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9841, Requested 735. Please try again in 3.456s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "9it [00:16,  1.17s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 576e4ead-9261-44f2-8447-1a07bfcaf2a9: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9795, Requested 780. Please try again in 3.45s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9795, Requested 780. Please try again in 3.45s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ab2af948-d422-4b6b-b2ab-f75bca5f4ed8: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9774, Requested 784. Please try again in 3.348s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9774, Requested 784. Please try again in 3.348s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 9463b661-98f7-41f7-b7ef-841b9451719b: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9939, Requested 684. Please try again in 3.738s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9939, Requested 684. Please try again in 3.738s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c65bfae7-8a2b-4f3c-a812-821a502f8899: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9811, Requested 819. Please try again in 3.78s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9811, Requested 819. Please try again in 3.78s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 1dc1a24a-8226-4f64-bff4-403a1ca940db: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9796, Requested 822. Please try again in 3.708s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9796, Requested 822. Please try again in 3.708s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f756f965-a5e8-4c81-9726-dbddbda02d0b: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9695, Requested 653. Please try again in 2.088s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9695, Requested 653. Please try again in 2.088s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 576e4ead-9261-44f2-8447-1a07bfcaf2a9: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9612, Requested 731. Please try again in 2.058s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9612, Requested 731. Please try again in 2.058s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "10it [00:24,  2.85s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run ab2af948-d422-4b6b-b2ab-f75bca5f4ed8: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9616, Requested 735. Please try again in 2.106s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9616, Requested 735. Please try again in 2.106s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 3be7edc1-048a-44a4-921d-797589d685e6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9528, Requested 819. Please try again in 2.082s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9528, Requested 819. Please try again in 2.082s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 9463b661-98f7-41f7-b7ef-841b9451719b: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9943, Requested 635. Please try again in 3.468s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9943, Requested 635. Please try again in 3.468s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "13it [00:26,  1.59s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run c65bfae7-8a2b-4f3c-a812-821a502f8899: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9809, Requested 770. Please try again in 3.474s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9809, Requested 770. Please try again in 3.474s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "14it [00:26,  1.31s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 1dc1a24a-8226-4f64-bff4-403a1ca940db: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9794, Requested 773. Please try again in 3.402s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9794, Requested 773. Please try again in 3.402s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "16it [00:29,  1.40s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 3be7edc1-048a-44a4-921d-797589d685e6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9809, Requested 770. Please try again in 3.474s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9809, Requested 770. Please try again in 3.474s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "17it [00:30,  1.21s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 0f55bbd8-8091-44ce-88f3-8248f3479a8e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9793, Requested 784. Please try again in 3.462s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9793, Requested 784. Please try again in 3.462s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 0747b040-19c2-4428-ba14-ed8e20efc3f0: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9790, Requested 784. Please try again in 3.444s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9790, Requested 784. Please try again in 3.444s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 86a382f5-e92f-410b-9e32-d1c5f08241d8: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9883, Requested 819. Please try again in 4.212s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 306, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9883, Requested 819. Please try again in 4.212s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "20it [00:43,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'CRITERIAL_EVALUATION-3c3b77d3' at:\n",
      "https://smith.langchain.com/o/4f4b6069-9fa7-4219-889b-6de7c9b52ea4/datasets/d27aef40-c129-4c8c-85da-f16249bcb82f/compare?selectedSessions=64524624-70a7-442a-b29a-109e8719a019\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Error running evaluator <DynamicRunEvaluator evaluate> on run 6c456f66-1fbd-4904-8d25-3aef061cb5ae: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9955, Requested 241. Please try again in 1.176s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9955, Requested 241. Please try again in 1.176s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 3c73ce06-7069-437a-89a2-f854d983b21f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9954, Requested 241. Please try again in 1.17s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9954, Requested 241. Please try again in 1.17s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 6c456f66-1fbd-4904-8d25-3aef061cb5ae: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9834, Requested 249. Please try again in 498ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9834, Requested 249. Please try again in 498ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a763690d-8230-4af3-a9dd-c6466dde1869: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9838, Requested 215. Please try again in 318ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9838, Requested 215. Please try again in 318ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 72edf424-1dcd-4c2b-9bbb-2bcde8f7935a: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9799, Requested 232. Please try again in 186ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9799, Requested 232. Please try again in 186ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 6c456f66-1fbd-4904-8d25-3aef061cb5ae: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9776, Requested 249. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9776, Requested 249. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "1it [00:08,  8.50s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 4702d707-3678-4979-8954-d871b530276e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9954, Requested 232. Please try again in 1.116s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9954, Requested 232. Please try again in 1.116s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8b403e9b-ed53-4bb4-8412-49be6a6191fd: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9864, Requested 220. Please try again in 503ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9864, Requested 220. Please try again in 503ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 72edf424-1dcd-4c2b-9bbb-2bcde8f7935a: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9962, Requested 232. Please try again in 1.164s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9962, Requested 232. Please try again in 1.164s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "2it [00:10,  4.76s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 4702d707-3678-4979-8954-d871b530276e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9967, Requested 232. Please try again in 1.194s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9967, Requested 232. Please try again in 1.194s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d5804f80-9f77-407a-927b-29cb711a1dc1: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9960, Requested 224. Please try again in 1.104s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9960, Requested 224. Please try again in 1.104s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e5b9e619-d093-4b03-9ae2-695d8cf1a5d8: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9943, Requested 258. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9943, Requested 258. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d5804f80-9f77-407a-927b-29cb711a1dc1: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9960, Requested 232. Please try again in 1.152s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9960, Requested 232. Please try again in 1.152s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4f7d10d8-8a95-4274-8c0d-ce443ef96e1e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9970, Requested 232. Please try again in 1.212s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9970, Requested 232. Please try again in 1.212s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e5b9e619-d093-4b03-9ae2-695d8cf1a5d8: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9939, Requested 258. Please try again in 1.182s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9939, Requested 258. Please try again in 1.182s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "5it [00:14,  2.17s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 4f7d10d8-8a95-4274-8c0d-ce443ef96e1e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9955, Requested 232. Please try again in 1.122s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9955, Requested 232. Please try again in 1.122s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "6it [00:16,  1.95s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 4e578507-81a6-4f85-a910-984a5f2537fd: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9965, Requested 224. Please try again in 1.134s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9965, Requested 224. Please try again in 1.134s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 3c73ce06-7069-437a-89a2-f854d983b21f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9943, Requested 249. Please try again in 1.152s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9943, Requested 249. Please try again in 1.152s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "9it [00:18,  1.11s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 52985364-066b-4728-8d1b-c036128f72a0: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9819, Requested 224. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9819, Requested 224. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4e578507-81a6-4f85-a910-984a5f2537fd: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9818, Requested 232. Please try again in 300ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9818, Requested 232. Please try again in 300ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 7e7760a6-321b-42ec-a709-05757fcd97b2: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9968, Requested 232. Please try again in 1.2s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9968, Requested 232. Please try again in 1.2s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c4c5d882-4648-4225-b8ec-9c04ba1460b1: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9967, Requested 241. Please try again in 1.248s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9967, Requested 241. Please try again in 1.248s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 41936f86-f732-4b22-a97c-7f2a02960fe3: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9969, Requested 232. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9969, Requested 232. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f68c5107-a6f0-4cdd-a15a-7869092b461d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9962, Requested 241. Please try again in 1.218s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9962, Requested 241. Please try again in 1.218s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c4c5d882-4648-4225-b8ec-9c04ba1460b1: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9821, Requested 249. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9821, Requested 249. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 7e7760a6-321b-42ec-a709-05757fcd97b2: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9809, Requested 232. Please try again in 246ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9809, Requested 232. Please try again in 246ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "10it [00:23,  2.15s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 41936f86-f732-4b22-a97c-7f2a02960fe3: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9976, Requested 232. Please try again in 1.248s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9976, Requested 232. Please try again in 1.248s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "11it [00:23,  1.63s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run f68c5107-a6f0-4cdd-a15a-7869092b461d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9944, Requested 249. Please try again in 1.158s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9944, Requested 249. Please try again in 1.158s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 291d4a68-1d6f-403d-b653-3bdb6cb030df: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9815, Requested 244. Please try again in 354ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9815, Requested 244. Please try again in 354ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c4c5d882-4648-4225-b8ec-9c04ba1460b1: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9820, Requested 249. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9820, Requested 249. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "12it [00:25,  1.59s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run e77b823b-e4c2-45a7-9e21-cd1821a3a817: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9957, Requested 241. Please try again in 1.188s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9957, Requested 241. Please try again in 1.188s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f68c5107-a6f0-4cdd-a15a-7869092b461d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9947, Requested 249. Please try again in 1.176s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9947, Requested 249. Please try again in 1.176s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "14it [00:26,  1.02s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 2274311c-49b3-4dc7-970b-f3e79aa91ea5: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9806, Requested 232. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9806, Requested 232. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 291d4a68-1d6f-403d-b653-3bdb6cb030df: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9785, Requested 252. Please try again in 222ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9785, Requested 252. Please try again in 222ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e77b823b-e4c2-45a7-9e21-cd1821a3a817: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9974, Requested 249. Please try again in 1.338s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9974, Requested 249. Please try again in 1.338s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e77b823b-e4c2-45a7-9e21-cd1821a3a817: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9952, Requested 249. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1384, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 329, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 614, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 611, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 446, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1044, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1093, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kangyeonjin\\miniforge3\\envs\\buzz\\Lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-bhhAVavshSkAZcM7eVekvSrb on tokens per min (TPM): Limit 10000, Used 9952, Requested 249. Please try again in 1.206s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "20it [00:50,  2.51s/it]\n"
     ]
    }
   ],
   "source": [
    "from rag import PDFRAG\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "rag = PDFRAG(\n",
    "    file_path=\"data/snow-white.pdf\", llm=ChatOpenAI(model_name=\"gpt-4o-mini\",temperature=0)\n",
    ")\n",
    "\n",
    "retriever = rag.create_retriever()\n",
    "\n",
    "chain = rag.create_chain(retriever)\n",
    "\n",
    "# chain.invoke(\"백설공주는 어떤 과일을 먹고 쓰러졌나요?\")\n",
    "\n",
    "# 질문에 답변하는 함수\n",
    "def ask_question(inputs : dict):\n",
    "    return {\"answer\" : chain.invoke(inputs[\"question\"])}\n",
    "\n",
    "# llm_answer = ask_question(\n",
    "#     {\"question\" : \"백설공주는 어떤 과일을 먹고 쓰러졌나요?\"}\n",
    "# )\n",
    "# llm_answer\n",
    "\n",
    "# evaluator prompt 출력을 위한 함수\n",
    "def print_evaluator_prompt(evaluator):\n",
    "    return evaluator.evaluator.prompt.pretty_print()\n",
    "\n",
    "# qa 평가자 생성\n",
    "qa_evaluator = LangChainStringEvaluator(\"qa\")\n",
    "\n",
    "print_evaluator_prompt(qa_evaluator)\n",
    "\n",
    "dataset_name = \"RAG_EVALUATION_DATASET\"\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    ask_question, # 평가할 함수 지정\n",
    "    data=dataset_name, # 데이터셋지정\n",
    "    evaluators=[qa_evaluator], # 평가자 지정\n",
    "    experiment_prefix=\"RAG_EVALUATION\", # 실험 이름 지정\n",
    "    metadata={\n",
    "        \"variant\" : \"QA Evaluator 를 활용한 평가\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Context를 반환하는 RAG 결과 반환 함수\n",
    "def rag_context_answer(inputs: dict):\n",
    "    context = retriever.invoke(inputs[\"question\"])\n",
    "    return {\n",
    "        \"context\":\"\\n\".join([doc.page_content for doc in context]),\n",
    "        \"answer\": chain.invoke(inputs[\"question\"]),\n",
    "        \"query\": inputs[\"question\"]\n",
    "    }\n",
    "\n",
    "rag_context_answer(\n",
    "    {\"question\": \"백설공주는 어떤 과일을 먹고 쓰러졌나요?\"}\n",
    ")\n",
    "\n",
    "# cot_qa 평가자\n",
    "cot_qa_evaluator = LangChainStringEvaluator(\n",
    "    \"cot_qa\",\n",
    "    prepare_data=lambda run, example : {\n",
    "        \"prediction\": run.outputs[\"answer\"], # LLM이 생성한답변\n",
    "        \"reference\": run.outputs[\"context\"], # Context\n",
    "        \"input\": example.inputs[\"question\"]  # 데이터셋의 질문\n",
    "    }\n",
    ")\n",
    "\n",
    "# context_qa 평가자\n",
    "context_qa_evaluator = LangChainStringEvaluator(\n",
    "    \"context_qa\",\n",
    "    prepare_data=lambda run, example : {\n",
    "        \"prediction\": run.outputs[\"answer\"], # LLM이 생성한답변\n",
    "        \"reference\": run.outputs[\"context\"], # Context\n",
    "        \"input\": example.inputs[\"question\"]  # 데이터셋의 질문\n",
    "    }\n",
    ")\n",
    "\n",
    "print_evaluator_prompt(cot_qa_evaluator)\n",
    "\n",
    "#데이터셋 이름\n",
    "dataset_name = \"RAG_EVALUATION_DATASET\"\n",
    "\n",
    "# 평가실행\n",
    "evaluate(\n",
    "    rag_context_answer,\n",
    "    data=dataset_name,\n",
    "    evaluators=[cot_qa_evaluator, context_qa_evaluator],\n",
    "    experiment_prefix=\"RAG_EVALUATION\",\n",
    "    metadata={\n",
    "        \"variant\" : \"COT_QA & CONTEXT_QA Evaluatior 를 활용한 평가\"\n",
    "    }\n",
    ")\n",
    "\n",
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# 평가자\n",
    "criteria_evaluator = [\n",
    "    LangChainStringEvaluator(\"criteria\", config={\"criteria\": \"conciseness\"}), # 간결성\n",
    "    LangChainStringEvaluator(\"criteria\", config={\"criteria\": \"misogyny\"}), # 여성 비하\n",
    "    LangChainStringEvaluator(\"criteria\", config={\"criteria\": \"criminality\"}) # 범죄 촉진\n",
    "]\n",
    "\n",
    "#데이터셋 이름 설정\n",
    "dataset_name = \"RAG_EVALUATION_DATASET\"\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=criteria_evaluator,\n",
    "    experiment_prefix=\"CRITERIAL_EVALUATION\",\n",
    "    metadata={\n",
    "        \"variant\": \"criteria를 활용한 평가\"\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
