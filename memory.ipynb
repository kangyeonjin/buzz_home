{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 안녕하셍 제추도여행을 계획중인데 추천해주실만한 곳이 있을까요?\n",
      "AI: 안녕하세요 제주도 여행을 도와드리게 되서 기쁩니다 언제 방문하시나요?\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"안녕하셍 제추도여행을 계획중인데 추천해주실만한 곳이 있을까요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\":\"안녕하세요 제주도 여행을 도와드리게 되서 기쁩니다 언제 방문하시나요?\"\n",
    "    }\n",
    ")\n",
    "\n",
    "memory\n",
    "\n",
    "print(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 안녕하셍 제추도여행을 계획중인데 추천해주실만한 곳이 있을까요?\n",
      "AI: 안녕하세요 제주도 여행을 도와드리게 되서 기쁩니다 언제 방문하시나요?\n",
      "Human: 5월 초에 3박 4일로 방문할 예정입니다.\n",
      "AI: 5월은 제주도의 봄을 만끽하기 좋은 시기입니다. 우도, 성산일출봉, 카페거리 등을 추천드립니다. 구체적인 일정을 함께 계획해볼까요?\n",
      "Human: 네, 일정 계획을 도와주시면 감사하겠습니다.\n",
      "AI: 첫째 날은 제주 공항에서 렌터카를 픽업하신 후, 함덕 해수욕장과 카페거리를 둘러보시는 것을 추천드립니다. 둘째 날은 성산일출봉과 우도 투어, 셋째 날은 한라산 등반이나 올레길 산책은 어떠신가요?\n"
     ]
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    inputs={\"human\": \"5월 초에 3박 4일로 방문할 예정입니다.\"},\n",
    "    outputs={\n",
    "        \"ai\": \"5월은 제주도의 봄을 만끽하기 좋은 시기입니다. 우도, 성산일출봉, 카페거리 등을 추천드립니다. 구체적인 일정을 함께 계획해볼까요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"네, 일정 계획을 도와주시면 감사하겠습니다.\"},\n",
    "    outputs={\n",
    "        \"ai\": \"첫째 날은 제주 공항에서 렌터카를 픽업하신 후, 함덕 해수욕장과 카페거리를 둘러보시는 것을 추천드립니다. 둘째 날은 성산일출봉과 우도 투어, 셋째 날은 한라산 등반이나 올레길 산책은 어떠신가요?\"\n",
    "    },\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kangyeonjin\\AppData\\Local\\Temp\\ipykernel_6792\\458341379.py:9: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 피자 주문을 도와드릴 수 있어서 기쁩니다. 다양한 종류의 피자가 있습니다. 몇 가지 인기 있는 피자를 소개해드릴게요:\n",
      "\n",
      "1. **마르게리타 피자**: 신선한 토마토 소스, 모짜렐라 치즈, 바질 잎이 올라간 클래식한 피자입니다.\n",
      "\n",
      "2. **페퍼로니 피자**: 매콤한 페퍼로니와 풍부한 치즈가 어우러진 피자로, 많은 사람들이 좋아하는 메뉴입니다.\n",
      "\n",
      "3. **하와이안 피자**: 햄과 파인애플이 올라가 달콤하고 짭짤한 맛이 특징입니다.\n",
      "\n",
      "4. **고르곤졸라 피자**: 고르곤졸라 치즈와 꿀이 조화를 이루어 독특한 맛을 제공합니다.\n",
      "\n",
      "5. **불고기 피자**: 한국식 불고기와 다양한 채소가 올라간 피자로, 한국적인 맛을 느낄 수 있습니다.\n",
      "\n",
      "이 외에도 다양한 토핑과 스타일로 피자를 커스터마이즈할 수 있습니다. 어떤 피자가 마음에 드시나요?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "response = conversation.predict(\n",
    "    input=\"안녕하세요 피자 한판 주문하고 싶은데 어떤 피자가 있나요?\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 이전 답변을 마크다운 형식으로 요약해드리겠습니다:\n",
      "\n",
      "- **마르게리타 피자**: 신선한 토마토 소스, 모짜렐라 치즈, 바질 잎이 올라간 클래식한 피자\n",
      "- **페퍼로니 피자**: 매콤한 페퍼로니와 풍부한 치즈가 어우러진 피자\n",
      "- **하와이안 피자**: 햄과 파인애플이 올라가 달콤하고 짭짤한 맛이 특징인 피자\n",
      "- **고르곤졸라 피자**: 고르곤졸라 치즈와 꿀이 조화를 이루어 독특한 맛을 제공하는 피자\n",
      "- **불고기 피자**: 한국식 불고기와 다양한 채소가 올라간 한국적인 맛의 피자\n",
      "\n",
      "이 외에도 다양한 토핑과 스타일로 피자를 커스터마이즈할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "response = conversation.predict(\n",
    "    input=\"이전 답변을 마크다운 형식으로 요약해서 정리해주세요\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='모짜렐라 치즈 추가로 주문할게요. 얼마인가요?', additional_kwargs={}, response_metadata={}), AIMessage(content='L사이즈 페퍼로니 피자(치즈크러스트) + 모짜렐라 치즈 추가는 총 28,000원입니다. 주문을 진행할까요?', additional_kwargs={}, response_metadata={}), HumanMessage(content='네, 주문할게요. 배달 시간은 얼마나 걸리나요?', additional_kwargs={}, response_metadata={}), AIMessage(content='주문이 완료되었습니다. 현재 예상 배달 시간은 약 40분입니다. 주문 현황은 문자메시지로 전송해 드리겠습니다. 감사합니다!', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kangyeonjin\\AppData\\Local\\Temp\\ipykernel_5704\\3389392884.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=2, return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2, return_messages=True)\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"안녕하세요, 피자 한 판 주문하고 싶은데요. 어떤 피자가 있나요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"안녕하세요! 저희 매장의 인기 메뉴로는 페퍼로니, 치즈, 하와이안, 콤비네이션 피자가 있습니다. 어떤 피자를 선호하시나요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"페퍼로니 피자로 할게요. 크기는 어떻게 되나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"페퍼로니 피자는 M(25cm), L(32cm), XL(40cm) 사이즈로 제공됩니다. 크기를 선택해 주세요.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"L 사이즈로 주문할게요. 도우는 어떤 종류가 있나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"도우는 일반, 씬, 치즈크러스트 중에서 선택하실 수 있습니다. 어떤 도우로 하시겠어요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"치즈크러스트로 할게요. 토핑 추가는 가능한가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"네, 추가 토핑으로 모짜렐라 치즈, 올리브, 버섯, 피망, 양파를 선택하실 수 있습니다. 추가하실 토핑이 있으신가요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"모짜렐라 치즈 추가로 주문할게요. 얼마인가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"L사이즈 페퍼로니 피자(치즈크러스트) + 모짜렐라 치즈 추가는 총 28,000원입니다. 주문을 진행할까요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"네, 주문할게요. 배달 시간은 얼마나 걸리나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"주문이 완료되었습니다. 현재 예상 배달 시간은 약 40분입니다. 주문 현황은 문자메시지로 전송해 드리겠습니다. 감사합니다!\"\n",
    "    },\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='네, 주문할게요. 배달 시간은 얼마나 걸리나요?', additional_kwargs={}, response_metadata={}), AIMessage(content='주문이 완료되었습니다. 현재 예상 배달 시간은 약 40분입니다. 주문 현황은 문자메시지로 전송해 드리겠습니다. 감사합니다!', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kangyeonjin\\AppData\\Local\\Temp\\ipykernel_8388\\3255263824.py:57: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주문 내역을 확인해 드리겠습니다. 고객님께서 주문하신 내역은 다음과 같습니다:\n",
      "\n",
      "1. **메뉴 이름**: 불고기 피자\n",
      "   - **수량**: 1\n",
      "   - **가격**: 15,000원\n",
      "\n",
      "2. **메뉴 이름**: 치킨 윙\n",
      "   - **수량**: 1\n",
      "   - **가격**: 8,000원\n",
      "\n",
      "3. **메뉴 이름**: 콜라 (500ml)\n",
      "   - **수량**: 2\n",
      "   - **가격**: 2,000원 (각 1,000원)\n",
      "\n",
      "총 주문 금액은 25,000원입니다. 주문에 대한 추가 정보나 변경 사항이 필요하시면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm = llm,\n",
    "    max_token_limit=100,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"안녕하세요, 피자 한 판 주문하고 싶은데요. 어떤 피자가 있나요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"안녕하세요! 저희 매장의 인기 메뉴로는 페퍼로니, 치즈, 하와이안, 콤비네이션 피자가 있습니다. 어떤 피자를 선호하시나요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"페퍼로니 피자로 할게요. 크기는 어떻게 되나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"페퍼로니 피자는 M(25cm), L(32cm), XL(40cm) 사이즈로 제공됩니다. 크기를 선택해 주세요.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"L 사이즈로 주문할게요. 도우는 어떤 종류가 있나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"도우는 일반, 씬, 치즈크러스트 중에서 선택하실 수 있습니다. 어떤 도우로 하시겠어요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"치즈크러스트로 할게요. 토핑 추가는 가능한가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"네, 추가 토핑으로 모짜렐라 치즈, 올리브, 버섯, 피망, 양파를 선택하실 수 있습니다. 추가하실 토핑이 있으신가요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"모짜렐라 치즈 추가로 주문할게요. 얼마인가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"L사이즈 페퍼로니 피자(치즈크러스트) + 모짜렐라 치즈 추가는 총 28,000원입니다. 주문을 진행할까요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"네, 주문할게요. 배달 시간은 얼마나 걸리나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"주문이 완료되었습니다. 현재 예상 배달 시간은 약 40분입니다. 주문 현황은 문자메시지로 전송해 드리겠습니다. 감사합니다!\"\n",
    "    },\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({})[\"history\"])\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "response = conversation.predict(\n",
    "    input=\"주문한 내역을 알려주세요\"\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{entities}\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Last line:\n",
      "Human: {input}\n",
      "You:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kangyeonjin\\AppData\\Local\\Temp\\ipykernel_8388\\501035820.py:36: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationEntityMemory(llm=llm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bear': 'Bear는 실리콘밸리의 유명 테크 기업에서 백엔드 아키텍트로 일하며, Tiger와 함께 개발한 대규모 언어 모델이 깃허브에서 10만 스타를 받아 오픈소스 커뮤니티에서 주목받고 있습니다.', 'Tiger': 'Tiger는 실리콘밸리의 유명 테크 기업에서 AI 엔지니어링 팀의 리더로 활동하며, 최근 개발한 대규모 언어 모델이 깃허브에서 10만 스타를 받아 오픈소스 커뮤니티에서 주목받고 있습니다.', '실리콘밸리': '실리콘밸리는 유명 테크 기업들이 위치한 지역으로, Bear와 Tiger 같은 개발자들이 활동하고 있습니다.', '깃허브': '깃허브는 Bear와 Tiger가 개발한 대규모 언어 모델이 10만 스타를 받으며 오픈소스 커뮤니티에서 주목받고 있는 플랫폼입니다.', '오픈소스 커뮤니티': '오픈소스 커뮤니티는 Bear와 Tiger가 개발한 대규모 언어 모델이 깃허브에서 10만 스타를 받으며 주목받고 있습니다.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "\n",
    "print(ENTITY_MEMORY_CONVERSATION_TEMPLATE.template)\n",
    "\n",
    "\"\"\"\n",
    "당신은 OpenAI가 훈련한 대규모 언어 모델을 기반으로 하는 인간의 어시스턴트입니다.\n",
    "\n",
    "당신은 다음과 같은 능력을 가지고 있습니다:\n",
    "- 간단한 질문에서부터 심도 있는 설명과 토론까지 다양한 작업 지원\n",
    "- 입력받은 내용을 바탕으로 자연스러운 대화가 가능한 텍스트 생성\n",
    "- 주제에 맞는 일관성 있고 관련성 높은 응답 제공\n",
    "\n",
    "당신의 특징:\n",
    "- 지속적인 학습과 개선\n",
    "- 대량의 텍스트 처리 및 이해 능력\n",
    "- Context 섹션에서 제공된 개인화된 정보 접근 가능\n",
    "- 입력을 바탕으로 한 자체 텍스트 생성 및 설명 능력\n",
    "\n",
    "대화 구조:\n",
    "Context: {entities} \n",
    "History: {history}\n",
    "Current input: {input}\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=ConversationEntityMemory(llm=llm)\n",
    ")\n",
    "\n",
    "conversation.predict(\n",
    "    input=\"Bear와 Tiger는 실리콘밸리의 유명 테크 기업 개발자입니다. \"\n",
    "    \"Bear는 백엔드 아키텍트이고 Tiger는 AI 엔지니어링 팀의 리더입니다. \"\n",
    "    \"그들은 최근 개발한 대규모 언어 모델이 깃허브에서 10만 스타를 받으며 오픈소스 커뮤니티에서 주목받고 있습니다.\"\n",
    ")\n",
    "\n",
    "print(conversation.memory.entity_store.store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bear': 'Bear는 실리콘밸리의 유명 테크 기업에서 백엔드 아키텍트로 일했으며, 은퇴 후 강사로 활동하고 있습니다. Tiger와 함께 개발한 대규모 언어 모델이 깃허브에서 10만 스타를 받아 오픈소스 커뮤니티에서 주목받고 있습니다.', 'Tiger': 'Tiger는 실리콘밸리의 유명 테크 기업에서 AI 엔지니어링 팀의 리더로 활동하며, 최근 개발한 대규모 언어 모델이 깃허브에서 10만 스타를 받아 오픈소스 커뮤니티에서 주목받고 있습니다.', '실리콘밸리': '실리콘밸리는 유명 테크 기업들이 위치한 지역으로, Bear와 Tiger 같은 개발자들이 활동하고 있습니다.', '깃허브': '깃허브는 Bear와 Tiger가 개발한 대규모 언어 모델이 10만 스타를 받으며 오픈소스 커뮤니티에서 주목받고 있는 플랫폼입니다.', '오픈소스 커뮤니티': '오픈소스 커뮤니티는 Bear와 Tiger가 개발한 대규모 언어 모델이 깃허브에서 10만 스타를 받으며 주목받고 있습니다.'}\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(\n",
    "    input=\"Bear는 은퇴해서 강사를 하고 있다고 해 \"\n",
    ")\n",
    "\n",
    "print(conversation.memory.entity_store.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kangyeonjin\\AppData\\Local\\Temp\\ipykernel_8388\\2222953399.py:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='The human asks about the price range of the latest smartphones. The AI responds that flagship smartphones start at around 1 million won, with prices varying up to 1.5 million won depending on storage and model. Mid-range models are available for 500,000 to 800,000 won. The human inquires about battery performance, and the AI explains that most latest models have batteries over 4500mAh, support fast charging, and can last all day with typical use. Charging can reach 50% in 30 minutes and full charge in an hour. The human then asks about camera performance, and the AI states that the main camera supports over 50MP, includes ultra-wide and telephoto lenses, and features AI image processing for excellent night photography, as well as 8K video recording capabilities. The human asks about the after-sales policy, and the AI explains that a 1-year free warranty is provided, which can be extended to 2 years with additional insurance. Repairs can be done at nationwide service centers, with simple repairs completed on the same day. The human inquires about 5G support and storage capacity, and the AI confirms that all latest models support 5G, with storage options ranging from 128GB to 1TB, and basic cloud storage services are also provided. The human asks about promotional gifts or discounts, and the AI mentions that wireless earphones are offered with purchases this month, up to a 10% discount is available with certain credit card partnerships, and additional discounts can be obtained through trade-in of old phones. The human asks about water resistance and durability, and the AI states that the phones have an IP68 rating, can withstand 1.5 meters of water for 30 minutes, feature Gorilla Glass for scratch resistance, and use aircraft-grade aluminum for enhanced durability.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"최신 스마트폰의 가격대가 어떻게 되나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"최신 플래그십 스마트폰의 기본 가격은 100만원대부터 시작합니다. 저장 용량과 모델에 따라 150만원까지 다양합니다. 중급형 모델은 50-80만원대에서 구매 가능합니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"배터리 성능은 어떤가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"최신 모델들은 대부분 4500mAh 이상의 배터리를 탑재하고 있으며, 고속 충전을 지원합니다. 일반적인 사용시 하루 종일 사용 가능하며, 충전 시간은 30분에 50%, 1시간에 완충이 가능합니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"카메라 성능은 어떤가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"메인 카메라는 50MP 이상을 지원하며, 울트라와이드와 망원 렌즈도 탑재되어 있습니다. AI 이미지 처리 기술로 야간 촬영도 우수하며, 8K 동영상 촬영도 가능합니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"AS 정책은 어떻게 되나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"기본적으로 1년 무상 보증이 제공되며, 추가 보험 가입시 2년까지 연장 가능합니다. 전국 서비스센터에서 수리가 가능하고, 간단한 수리는 당일 처리됩니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"5G 지원과 저장 용량은 어떻게 되나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"모든 최신 모델이 5G를 지원하며, 저장 용량은 128GB부터 시작해서 1TB까지 선택 가능합니다. 클라우드 저장소 서비스도 기본 제공됩니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"구매시 사은품이나 할인 혜택이 있나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"이번 달 구매시 무선이어폰이 증정되며, 카드사 제휴 할인시 최대 10% 할인이 가능합니다. 또한 기존 폰 보상 판매시 추가 할인도 받으실 수 있습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"방수 등급과 내구성은 어떤가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"IP68 등급으로 1.5미터 깊이의 물에서 30분간 견딜 수 있으며, 고릴라 글래스 적용으로 스크래치에 강합니다. 또한 프레임은 항공기급 알루미늄을 사용해 내구성이 뛰어납니다.\"\n",
    "    },\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='자동차 렌트 비용은 얼마인가요?', additional_kwargs={}, response_metadata={}), AIMessage(content='저희 렌트카의 기본 대여 비용은 하루 5만원입니다. 여기에는 기본 보험료와 GPS 네비게이션이 포함되어있습니다.차종에따라 추가 비용이 발생 할 수 있으며, 장기 렌트시 할인 혜택이 제공됩니다', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kangyeonjin\\AppData\\Local\\Temp\\ipykernel_8388\\553837796.py:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=200, # 요약의 기준\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"자동차 렌트 비용은 얼마인가요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"저희 렌트카의 기본 대여 비용은 하루 5만원입니다. 여기에는 기본 보험료와 GPS 네비게이션이 포함되어있습니다.\"\n",
    "        \"차종에따라 추가 비용이 발생 할 수 있으며, 장기 렌트시 할인 혜택이 제공됩니다\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({})[\"history\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='The human asks about the cost of renting a car. The AI responds that the basic rental cost is 50,000 won per day, which includes basic insurance and a GPS navigation system. Additional costs may apply depending on the car model, and discounts are available for long-term rentals. The AI further explains that they offer a variety of car types, including compact cars starting at 30,000 won per day, mid-sized cars at 50,000 won, SUVs at 70,000 won, and vans at 100,000 won. The human then inquires about the types and costs of insurance.', additional_kwargs={}, response_metadata={}), AIMessage(content='기본 보험은 대인/대물 보험이 포함되어 있으며, 추가로 자차 보험은 일 1만원, 완전 종합보험은 일 2만원입니다. 장기 렌트 시 보험료 할인 혜택도 제공됩니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='카시트 대여도 가능한가요?', additional_kwargs={}, response_metadata={}), AIMessage(content='네, 카시트 대여가 가능합니다. 영유아용/어린이용 카시트를 구비하고 있으며, 일 1만원의 비용으로 대여 가능합니다. 사전 예약을 추천드립니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='연료는 어떻게 반납해야 하나요?', additional_kwargs={}, response_metadata={}), AIMessage(content='차량 인수 시와 동일한 연료량으로 반납하셔야 합니다. 연료가 부족할 경우 실제 주유비에 추가 서비스 요금이 부과됩니다. 인근 주유소 위치는 저희가 안내해 드립니다.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    inputs={\"human\": \"차량 종류는 어떤 것이 있나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"저희 렌터카는 경차, 중형차, SUV, 승합차 등 다양한 차종을 보유하고 있습니다. 경차는 일 3만원부터, 중형차는 5만원부터, SUV는 7만원부터, 승합차는 10만원부터 시작합니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"보험 종류와 비용은 어떻게 되나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"기본 보험은 대인/대물 보험이 포함되어 있으며, 추가로 자차 보험은 일 1만원, 완전 종합보험은 일 2만원입니다. 장기 렌트 시 보험료 할인 혜택도 제공됩니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"카시트 대여도 가능한가요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"네, 카시트 대여가 가능합니다. 영유아용/어린이용 카시트를 구비하고 있으며, 일 1만원의 비용으로 대여 가능합니다. 사전 예약을 추천드립니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"연료는 어떻게 반납해야 하나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"차량 인수 시와 동일한 연료량으로 반납하셔야 합니다. 연료가 부족할 경우 실제 주유비에 추가 서비스 요금이 부과됩니다. 인근 주유소 위치는 저희가 안내해 드립니다.\"\n",
    "    },\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[SystemMessage(content='The human asks about the cost of renting a car. The AI responds that the basic rental cost is 50,000 won per day, which includes basic insurance and a GPS navigation system. Additional costs may apply depending on the car model, and discounts are available for long-term rentals. The AI further explains that they offer a variety of car types, including compact cars starting at 30,000 won per day, mid-sized cars at 50,000 won, SUVs at 70,000 won, and vans at 100,000 won. The human then inquires about the types and costs of insurance.', additional_kwargs={}, response_metadata={}), AIMessage(content='기본 보험은 대인/대물 보험이 포함되어 있으며, 추가로 자차 보험은 일 1만원, 완전 종합보험은 일 2만원입니다. 장기 렌트 시 보험료 할인 혜택도 제공됩니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='카시트 대여도 가능한가요?', additional_kwargs={}, response_metadata={}), AIMessage(content='네, 카시트 대여가 가능합니다. 영유아용/어린이용 카시트를 구비하고 있으며, 일 1만원의 비용으로 대여 가능합니다. 사전 예약을 추천드립니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='연료는 어떻게 반납해야 하나요?', additional_kwargs={}, response_metadata={}), AIMessage(content='차량 인수 시와 동일한 연료량으로 반납하셔야 합니다. 연료가 부족할 경우 실제 주유비에 추가 서비스 요금이 부과됩니다. 인근 주유소 위치는 저희가 안내해 드립니다.', additional_kwargs={}, response_metadata={})]\n",
      "Human: 차량 종류를 알려주세요\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "저희는 다양한 차량 종류를 제공하고 있습니다. 먼저, 컴팩트 카는 주로 도시 주행에 적합하며, 일 30,000원부터 시작합니다. 중형차는 좀 더 넓은 공간과 편안함을 제공하며, 일 50,000원입니다. SUV는 넓은 실내 공간과 강력한 주행 성능을 자랑하며, 일 70,000원에 대여 가능합니다. 마지막으로, 대가족이나 단체 여행에 적합한 밴은 일 100,000원에 대여할 수 있습니다. 각 차량은 기본적으로 GPS 내비게이션 시스템과 기본 보험이 포함되어 있습니다. 추가로 원하는 옵션이 있으시면 언제든지 문의해 주세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = conversation.predict(\n",
    "    input=\"차량 종류를 알려주세요\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kangyeonjin\\AppData\\Local\\Temp\\ipykernel_8388\\416257682.py:16: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = VectorStoreRetrieverMemory(retriever=retriever)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: 안녕하세요, 오늘 면접에 참석해주셔서 감사합니다. 자기소개 부탁드립니다.\n",
      "ai: 안녕하세요. 저는 경영학을 전공했지만 개발에 대한 열정으로 독학하여 개발자가 된 신입입니다. 부트캠프를 통해 웹 개발을 배웠고, 현재는 자바스크립트와 리액트를 주로 사용하여 개발하고 있습니다.\n",
      "human: 팀 프로젝트에서 어려움을 겪었던 경험이 있다면 어떻게 해결했나요?\n",
      "ai: 비전공자로서 기술적 지식이 부족한 부분이 있었지만, 이를 극복하기 위해 매일 2시간씩 추가 학습을 하고 팀원들에게 적극적으로 질문했습니다. 또한 제가 가진 경영학 지식을 활용하여 사용자 관점에서의 피드백을 제공하고, 프로젝트의 비즈니스 가치를 높이는데 기여했습니다.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "embedding_size = 1536\n",
    "\n",
    "index =faiss.IndexFlat(embedding_size)\n",
    "\n",
    "vectorstore = FAISS(embeddings_model, index, InMemoryDocstore({}),{})\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"안녕하세요, 오늘 면접에 참석해주셔서 감사합니다. 자기소개 부탁드립니다.\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"안녕하세요. 저는 경영학을 전공했지만 개발에 대한 열정으로 독학하여 개발자가 된 신입입니다. 부트캠프를 통해 웹 개발을 배웠고, 현재는 자바스크립트와 리액트를 주로 사용하여 개발하고 있습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"프로젝트에서 어떤 역할을 맡았나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"부트캠프 팀 프로젝트에서 프론트엔드 개발을 담당했습니다. 사용자 인터페이스 구현과 API 연동을 맡았으며, 특히 반응형 웹 디자인과 사용자 경험 개선에 중점을 두었습니다. 또한 기획 단계에서부터 참여하여 서비스의 전반적인 방향성 설정에도 기여했습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"팀 프로젝트에서 어려움을 겪었던 경험이 있다면 어떻게 해결했나요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"비전공자로서 기술적 지식이 부족한 부분이 있었지만, 이를 극복하기 위해 매일 2시간씩 추가 학습을 하고 팀원들에게 적극적으로 질문했습니다. 또한 제가 가진 경영학 지식을 활용하여 사용자 관점에서의 피드백을 제공하고, 프로젝트의 비즈니스 가치를 높이는데 기여했습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"개발자로서 자신의 강점은 무엇이라고 생각하나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"제 가장 큰 강점은 새로운 기술을 배우는 것에 대한 열정과 끊임없는 학습 의지입니다. 비전공자로서 처음 개발을 시작했을 때부터 지금까지 꾸준히 공부하며 성장해왔고, 앞으로도 계속해서 발전하고자 하는 마음가짐을 가지고 있습니다. 이러한 학습에 대한 열정을 바탕으로 빠르게 변화하는 기술 트렌드에도 잘 적응할 수 있으며, 문제 해결 능력도 지속적으로 향상시키고 있습니다.\"\n",
    "    },\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({\"human\" : \"면접자의 경험은 무엇인가요?\"})[\"history\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "chat_message_history = SQLChatMessageHistory(\n",
    "    session_id=\"sql_history\",\n",
    "    connection=\"sqlite:///sqlite.db\"\n",
    ")\n",
    "\n",
    "chat_message_history.add_user_message(\n",
    "    \"안녕? 만나서 반가워 나는 Bear야\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'당신의 이름은 Bear라고 하셨습니다. 맞나요?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables.utils import ConfigurableFieldSpec\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | ChatOpenAI(temperature=0, model=\"gpt-4o\") | StrOutputParser()\n",
    "\n",
    "def get_chat_history(user_id, conversation_id):\n",
    "    return SQLChatMessageHistory(\n",
    "        table_name=user_id,\n",
    "        session_id=conversation_id,\n",
    "        connection=\"sqlite:///sqlite.db\"\n",
    "    )\n",
    "    \n",
    "config_field = [\n",
    "    ConfigurableFieldSpec(\n",
    "        id=\"user_id\", # 설정값의 고유 식별자\n",
    "        annotation=str, # 설정값의 데이터 타입\n",
    "        name=\"USER ID\", # 설정값의 이름\n",
    "        description=\"Unique identifier for a user\", # 설정값에 대한 설명\n",
    "        default=\"\", # 기본값\n",
    "        is_shared=True # 여러 대화에서 공유되는 값인지 여부\n",
    "    ),\n",
    "    ConfigurableFieldSpec(\n",
    "        id=\"conversation_id\",\n",
    "        annotation=str,\n",
    "        name=\"CONVERSATION ID\",\n",
    "        description=\"Unique identifier for a conversation\",\n",
    "        default=\"\",\n",
    "        is_shared=True\n",
    "    )\n",
    "]\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_chat_history, # 대화기록을 가져오는 함수\n",
    "    input_messages_key=\"question\", # 입력 메시지 키\n",
    "    history_messages_key=\"chat_history\", # 대화 기록 메시지의 키\n",
    "    history_factory_config = config_field # 대화기록 조회시 참고할 파라미터\n",
    ")\n",
    "\n",
    "config  = {\"configurable\": {\"user_id\": \"user1\", \"conversation_id\": \"conversation1\"}}\n",
    "\n",
    "chain_with_history.invoke({\"question\" : \"안녕 반가워 내이름은 bear야\"}, config)\n",
    "\n",
    "config  = {\"configurable\": {\"user_id\": \"user1\", \"conversation_id\": \"conversation1\"}}\n",
    "\n",
    "chain_with_history.invoke({\"question\" : \"내이름이 뭐라고?\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
