{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language'] input_types={} partial_variables={} template='{language} ì–¸ì–´ì— ëŒ€í•´ 3ì¤„ë¡œ ì„¤ëª…í•´ì¤˜.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Python ì–¸ì–´ì— ëŒ€í•´ 3ì¤„ë¡œ ì„¤ëª…í•´ì¤˜.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"prompts/language_simple.yaml\", encoding=\"utf-8\")\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "prompt.format(language=\"Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. íŠ¹ì§•: ìë°”ëŠ” ê°ì²´ ì§€í–¥ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ, í”Œë«í¼ ë…ë¦½ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤. \"í•œ ë²ˆ ì‘ì„±í•˜ë©´ ì–´ë””ì„œë‚˜ ì‹¤í–‰ëœë‹¤\"ëŠ” ìŠ¬ë¡œê±´ ì•„ë˜, JVM(Java Virtual Machine)ì„ í†µí•´ ë‹¤ì–‘í•œ ìš´ì˜ì²´ì œì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤. ê°•ë ¥í•œ ë©”ëª¨ë¦¬ ê´€ë¦¬ì™€ ì˜ˆì™¸ ì²˜ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•˜ë©°, ë©€í‹°ìŠ¤ë ˆë”©ì„ ì§€ì›í•˜ì—¬ íš¨ìœ¨ì ì¸ ë™ì‹œ ì‘ì—…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. ì œì‘ì: ìë°”ëŠ” 1995ë…„ ì¬ ë§ˆì´í¬ë¡œì‹œìŠ¤í…œì¦ˆ(Sun Microsystems)ì˜ ì œì„ìŠ¤ ê³ ìŠ¬ë§(James Gosling)ì— ì˜í•´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. ëŒ€í‘œì ì¸ í”„ë ˆì„ì›Œí¬: ìŠ¤í”„ë§(Spring), í•˜ì´ë²„ë„¤ì´íŠ¸(Hibernate), ìë°” EE(Java EE) ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. ë§ì´ ì‚¬ìš©ë˜ëŠ” ë¶„ì•¼: ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜, ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜(Android), ê¸°ì—…ìš© ì†Œí”„íŠ¸ì›¨ì–´, ë¹…ë°ì´í„° ì²˜ë¦¬ ë° í´ë¼ìš°ë“œ ì»´í“¨íŒ… ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt2 = load_prompt(\"prompts/language.yaml\", encoding=\"utf-8\")\n",
    "\n",
    "chain = prompt2 | ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.0) | StrOutputParser()\n",
    "\n",
    "answer = chain.invoke(\"Java\")\n",
    "\n",
    "print(answer)\n",
    "# print(prompt2.format(language=\"Python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='{language}ì˜ ì œì‘ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"{language}ì˜ ì œì‘ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\")\n",
    "\n",
    "print(chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: pythonì˜ ì œì‘ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"{language}ì˜ ì œì‘ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\")\n",
    "\n",
    "print(chat_prompt.format(language=\"python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì¸ê³µì§€ëŠ¥ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì´ë¦„ì€ ì‹¬ìŠ¨ ì…ë‹ˆë‹¤', additional_kwargs={}, response_metadata={}), HumanMessage(content='ë°˜ê°€ì›Œìš”', additional_kwargs={}, response_metadata={}), AIMessage(content='ì•ˆë…•í•˜ì„¸ìš” ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”', additional_kwargs={}, response_metadata={}), HumanMessage(content='ë‹¹ì‹ ì˜ ì´ë¦„ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì¸ê³µì§€ëŠ¥ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì´ë¦„ì€ {name} ì…ë‹ˆë‹¤\"),\n",
    "        (\"human\",\"ë°˜ê°€ì›Œìš”\"),\n",
    "        (\"ai\", \"ì•ˆë…•í•˜ì„¸ìš” ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”\"),\n",
    "        (\"human\",\"{user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    name=\"ì‹¬ìŠ¨\", user_input=\"ë‹¹ì‹ ì˜ ì´ë¦„ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ\"\n",
    ")\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì œ ì´ë¦„ì€ ë²„ì¦ˆ ë¼ì´íŠ¸ì´ì–´ì…ë‹ˆë‹¤! ìš°ì£¼ë¥¼ íƒí—˜í•˜ê³  ëª¨í—˜ì„ ì¦ê¸°ëŠ” ìš°ì£¼ ì •ë³µìì£ . ë‹¹ì‹ ì€ ëˆ„êµ¬ì‹ ê°€ìš”?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì• ë‹ˆë©”ì´ì…˜ ë²„ì¦ˆë¼ì´íŠ¸ì´ì–´ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì´ë¦„ì€ {name} ì…ë‹ˆë‹¤\"),\n",
    "        (\"human\",\"ë°˜ê°€ì›Œìš”\"),\n",
    "        (\"ai\", \"ì•ˆë…•í•˜ì„¸ìš” ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”\"),\n",
    "        (\"human\",\"{user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    name=\"ë²„ì¦ˆ\", user_input=\"ë‹¹ì‹ ì˜ ì´ë¦„ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ\"\n",
    ")\n",
    "\n",
    "print(llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['conversation', 'word_count'] input_types={'conversation': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001FA021BA840>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ìš”ì•½ì „ë¬¸ aiì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ìš”í‚¤ì›Œë“œë¡œ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.'), additional_kwargs={}), MessagesPlaceholder(variable_name='conversation'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], input_types={}, partial_variables={}, template='ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ {word_count}ë‹¨ì–´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ ìš”ì•½ì „ë¬¸ aiì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ìš”í‚¤ì›Œë“œë¡œ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "        (\"human\", \"ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ {word_count}ë‹¨ì–´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_core.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"type\":\"missing\",\"loc\":[\"type\"],\"msg\":\"Field required\",\"input\":{\"content\":\"í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€\",\"role\":\"human\"},\"url\":\"https://errors.pydantic.dev/2.9/v/missing\"}]\n"
     ]
    }
   ],
   "source": [
    "from pydantic import ValidationError\n",
    "\n",
    "# ë‹¨ìˆœí™”ëœ BaseMessage ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "try:\n",
    "    message = BaseMessage(role=\"human\", content=\"í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€\")\n",
    "    print(message)\n",
    "except ValidationError as e:\n",
    "    print(e.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role='human' content='í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, ValidationError\n",
    "from typing import Union\n",
    "\n",
    "class BaseMessage(BaseModel):\n",
    "    role: str\n",
    "    content: Union[str, list[Union[str, dict]]]\n",
    "\n",
    "# BaseMessage ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "try:\n",
    "    message = BaseMessage(role=\"human\", content=\"í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€\")\n",
    "    print(message)\n",
    "except ValidationError as e:\n",
    "    print(e.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (0.3.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain-community)\n",
      "  Using cached SQLAlchemy-2.0.35-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-community) (3.11.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-community) (0.3.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-community) (0.3.18)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-community) (0.1.143)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.17.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kangyeonjin\\miniforge3\\envs\\buzz\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Using cached SQLAlchemy-2.0.35-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Installing collected packages: SQLAlchemy\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.36\n",
      "    Uninstalling SQLAlchemy-2.0.36:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.36\n",
      "Successfully installed SQLAlchemy-2.0.35\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: ë‹¹ì‹ ì€ ìš”ì•½ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ ëŒ€í™”ë¥¼ ì£¼ìš” í‚¤ì›Œë“œë¡œ ìš”ì•½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
      "Human: íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µëœ ìˆ«ìë¥¼ ì œê±°í•˜ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•˜ë©´ ë ê¹Œ?\n",
      "AI: ì•„ì£¼ ê°„ë‹¨í•´ìš”! set()ì„ ì‚¬ìš©í•˜ë©´ ì¤‘ë³µì„ ì‰½ê²Œ ì œê±°í•  ìˆ˜ ìˆë‹µë‹ˆë‹¤.\n",
      "Human: set()ì´ ë­”ì§€ëŠ” ì˜ ëª¨ë¥´ê² ì§€ë§Œ ì—„ì²­ ê°„ë‹¨í•˜ë„¤! ì´ê±¸ë¡œ í•´ê²°ëì–´ ã…ã…\n",
      "AI: ë„¤, setì€ ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ìë£Œí˜•ì´ì—ìš”! ì •ë§ ìœ ìš©í•˜ì£ . ì•ìœ¼ë¡œë„ íŒŒì´ì¬ì˜ í¸ë¦¬í•œ ê¸°ëŠ¥ë“¤ì„ ë§ì´ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆì–´ìš”~ ğŸ˜Š\n",
      "Human: ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ 5 ë‹¨ì–´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'íŒŒì´ì¬, ë¦¬ìŠ¤íŠ¸, ì¤‘ë³µ ì œê±°, set.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ëŒ€í™” ë‚´ìš©ì„ í¬í•¨í•œ í…œí”Œë¦¿ ìƒì„±\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ ìš”ì•½ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ ëŒ€í™”ë¥¼ ì£¼ìš” í‚¤ì›Œë“œë¡œ ìš”ì•½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"),  # ëŒ€í™” ë‚´ìš© ìë¦¬ í‘œì‹œì\n",
    "        (\"human\", \"ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ {word_count} ë‹¨ì–´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤\")  # ìš”ì•½ì„ ìš”ì²­\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ëŒ€í™” ë‚´ìš©ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ í•©ì¹¨, BaseMessage í˜•ì‹ì— ë§ê²Œ ì‘ì„±\n",
    "conversation = [\n",
    "    BaseMessage(role=\"human\", content=\"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µëœ ìˆ«ìë¥¼ ì œê±°í•˜ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•˜ë©´ ë ê¹Œ?\", type=\"text\"),\n",
    "    BaseMessage(role=\"ai\", content=\"ì•„ì£¼ ê°„ë‹¨í•´ìš”! set()ì„ ì‚¬ìš©í•˜ë©´ ì¤‘ë³µì„ ì‰½ê²Œ ì œê±°í•  ìˆ˜ ìˆë‹µë‹ˆë‹¤.\", type=\"text\"),\n",
    "    BaseMessage(role=\"human\", content=\"set()ì´ ë­”ì§€ëŠ” ì˜ ëª¨ë¥´ê² ì§€ë§Œ ì—„ì²­ ê°„ë‹¨í•˜ë„¤! ì´ê±¸ë¡œ í•´ê²°ëì–´ ã…ã…\", type=\"text\"),\n",
    "    BaseMessage(role=\"ai\", content=\"ë„¤, setì€ ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ìë£Œí˜•ì´ì—ìš”! ì •ë§ ìœ ìš©í•˜ì£ . ì•ìœ¼ë¡œë„ íŒŒì´ì¬ì˜ í¸ë¦¬í•œ ê¸°ëŠ¥ë“¤ì„ ë§ì´ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆì–´ìš”~ ğŸ˜Š\", type=\"text\")\n",
    "]\n",
    "\n",
    "# 'conversation'ì„ í…ìŠ¤íŠ¸ë¡œ ì „ë‹¬í•˜ê³ , 'word_count'ëŠ” 5ë¡œ ì„¤ì •\n",
    "formatted_chat_prompt = chat_prompt.format(\n",
    "    word_count=5,\n",
    "    conversation=[msg.dict() for msg in conversation]  # ëŒ€í™” ë‚´ìš© í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ì „ë‹¬\n",
    ")\n",
    "\n",
    "print(formatted_chat_prompt)\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "input = {\n",
    "    \"word_count\":5,\n",
    "    \"conversation\":[\n",
    "        (\"human\", \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µëœ ìˆ«ìë¥¼ ì œê±°í•˜ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•˜ë©´ ë ê¹Œ?\"),\n",
    "        (\"ai\", \"ì•„ì£¼ ê°„ë‹¨í•´ìš”! set()ì„ ì‚¬ìš©í•˜ë©´ ì¤‘ë³µì„ ì‰½ê²Œ ì œê±°í•  ìˆ˜ ìˆë‹µë‹ˆë‹¤.\"),\n",
    "        (\"human\", \"set()ì´ ë­”ì§€ëŠ” ì˜ ëª¨ë¥´ê² ì§€ë§Œ ì—„ì²­ ê°„ë‹¨í•˜ë„¤! ì´ê±¸ë¡œ í•´ê²°ëì–´ ã…ã…\"),\n",
    "        (\"ai\", \"ë„¤, setì€ ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ìë£Œí˜•ì´ì—ìš”! ì •ë§ ìœ ìš©í•˜ì£ . ì•ìœ¼ë¡œë„ íŒŒì´ì¬ì˜ í¸ë¦¬í•œ ê¸°ëŠ¥ë“¤ì„ ë§ì´ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆì–´ìš”~ ğŸ˜Š\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "chain.invoke(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'íŒŒì´ì¬, ë¦¬ìŠ¤íŠ¸, ì¤‘ë³µ ì œê±°, set.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ ìš”ì•½ì „ë¬¸ aiì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ìš”í‚¤ì›Œë“œë¡œ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "        (\"human\", \"ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ {word_count}ë‹¨ì–´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "input = {\n",
    "    \"word_count\":5,\n",
    "    \"conversation\":[\n",
    "        (\"human\", \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µëœ ìˆ«ìë¥¼ ì œê±°í•˜ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•˜ë©´ ë ê¹Œ?\"),\n",
    "        (\"ai\", \"ì•„ì£¼ ê°„ë‹¨í•´ìš”! set()ì„ ì‚¬ìš©í•˜ë©´ ì¤‘ë³µì„ ì‰½ê²Œ ì œê±°í•  ìˆ˜ ìˆë‹µë‹ˆë‹¤.\"),\n",
    "        (\"human\", \"set()ì´ ë­”ì§€ëŠ” ì˜ ëª¨ë¥´ê² ì§€ë§Œ ì—„ì²­ ê°„ë‹¨í•˜ë„¤! ì´ê±¸ë¡œ í•´ê²°ëì–´ ã…ã…\"),\n",
    "        (\"ai\", \"ë„¤, setì€ ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ìë£Œí˜•ì´ì—ìš”! ì •ë§ ìœ ìš©í•˜ì£ . ì•ìœ¼ë¡œë„ íŒŒì´ì¬ì˜ í¸ë¦¬í•œ ê¸°ëŠ¥ë“¤ì„ ë§ì´ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆì–´ìš”~ ğŸ˜Š\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community.llm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ollama\n\u001b[0;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m Ollama(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma2:9b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì§€êµ¬ì˜ ìì „ì£¼ê¸°ëŠ”?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community.llm'"
     ]
    }
   ],
   "source": [
    "from langchain_community.llm import Ollama\n",
    "\n",
    "llm = Ollama(model=\"gemma2:9b\")\n",
    "\n",
    "response = llm.invoke(\"ì§€êµ¬ì˜ ìì „ì£¼ê¸°ëŠ”?\")\n",
    "\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
